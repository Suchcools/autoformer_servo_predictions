{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='weather_96_96', model='Autoformer', data='custom', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='T (degC)', freq='h', checkpoints='./checkpoints/', seq_len=6, label_len=6, pred_len=1, bucket_size=4, n_hashes=4, enc_in=21, dec_in=21, c_out=21, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=2, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Autoformer_custom_ftM_sl6_ll6_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 36881\n",
      "val 5270\n",
      "test 10539\n",
      "\titers: 100, epoch: 1 | loss: 0.1135090\n",
      "\tspeed: 0.0533s/iter; left time: 117.6342s\n",
      "\titers: 200, epoch: 1 | loss: 0.1207157\n",
      "\tspeed: 0.0426s/iter; left time: 89.6264s\n",
      "\titers: 300, epoch: 1 | loss: 0.3012124\n",
      "\tspeed: 0.0434s/iter; left time: 86.9231s\n",
      "\titers: 400, epoch: 1 | loss: 0.2385478\n",
      "\tspeed: 0.0450s/iter; left time: 85.6768s\n",
      "\titers: 500, epoch: 1 | loss: 0.2457085\n",
      "\tspeed: 0.0458s/iter; left time: 82.6064s\n",
      "\titers: 600, epoch: 1 | loss: 0.1757226\n",
      "\tspeed: 0.0456s/iter; left time: 77.7971s\n",
      "\titers: 700, epoch: 1 | loss: 0.0491602\n",
      "\tspeed: 0.0517s/iter; left time: 82.9391s\n",
      "\titers: 800, epoch: 1 | loss: 0.0678918\n",
      "\tspeed: 0.0521s/iter; left time: 78.4120s\n",
      "\titers: 900, epoch: 1 | loss: 0.0708482\n",
      "\tspeed: 0.0540s/iter; left time: 75.9369s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0637040\n",
      "\tspeed: 0.0510s/iter; left time: 66.5375s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0560951\n",
      "\tspeed: 0.0512s/iter; left time: 61.7379s\n",
      "Epoch: 1 cost time: 56.4304678440094\n",
      "Epoch: 1, Steps: 1152 | Train Loss: 0.2975199 Vali Loss: 0.0988357 Test Loss: 0.0354988\n",
      "Validation loss decreased (inf --> 0.098836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1024657\n",
      "\tspeed: 0.1516s/iter; left time: 159.5918s\n",
      "\titers: 200, epoch: 2 | loss: 0.0310509\n",
      "\tspeed: 0.0367s/iter; left time: 34.9936s\n",
      "\titers: 300, epoch: 2 | loss: 0.0373857\n",
      "\tspeed: 0.0358s/iter; left time: 30.5558s\n",
      "\titers: 400, epoch: 2 | loss: 0.3235483\n",
      "\tspeed: 0.0417s/iter; left time: 31.3886s\n",
      "\titers: 500, epoch: 2 | loss: 0.0434124\n",
      "\tspeed: 0.0464s/iter; left time: 30.3170s\n",
      "\titers: 600, epoch: 2 | loss: 0.1025648\n",
      "\tspeed: 0.0465s/iter; left time: 25.6897s\n",
      "\titers: 700, epoch: 2 | loss: 0.0871541\n",
      "\tspeed: 0.0438s/iter; left time: 19.8474s\n",
      "\titers: 800, epoch: 2 | loss: 0.0836730\n",
      "\tspeed: 0.0515s/iter; left time: 18.1947s\n",
      "\titers: 900, epoch: 2 | loss: 0.0453601\n",
      "\tspeed: 0.0547s/iter; left time: 13.8509s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1216895\n",
      "\tspeed: 0.0549s/iter; left time: 8.3990s\n",
      "\titers: 1100, epoch: 2 | loss: 0.6142059\n",
      "\tspeed: 0.0518s/iter; left time: 2.7447s\n",
      "Epoch: 2 cost time: 53.77424693107605\n",
      "Epoch: 2, Steps: 1152 | Train Loss: 0.2478280 Vali Loss: 0.0954811 Test Loss: 0.0363700\n",
      "Validation loss decreased (0.098836 --> 0.095481).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      ">>>>>>>testing : weather_96_96_Autoformer_custom_ftM_sl6_ll6_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 10539\n",
      "test shape: (329, 32, 1, 21) (329, 32, 1, 21)\n",
      "test shape: (10528, 1, 21) (10528, 1, 21)\n",
      "mse:0.03644402325153351, mae:0.07355925440788269\n"
     ]
    }
   ],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=0\n",
    "! python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/weather/ \\\n",
    "  --data_path weather.csv \\\n",
    "  --model_id weather_96_96 \\\n",
    "  --model Autoformer \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 6 \\\n",
    "  --label_len 6 \\\n",
    "  --pred_len 1 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 21 \\\n",
    "  --dec_in 21 \\\n",
    "  --c_out 21 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --train_epochs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='creep', model='Autoformer', data='custom', root_path='./dataset/', data_path='rawdata.csv', features='M', target='y3', freq='h', checkpoints='./checkpoints/', seq_len=6, label_len=6, pred_len=1, bucket_size=4, n_hashes=4, enc_in=6, dec_in=6, c_out=6, d_model=512, n_heads=8, e_layers=1, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=2, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : creep_Autoformer_custom_ftM_sl6_ll6_pl1_dm512_nh8_el1_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 305\n",
      "val 45\n",
      "test 89\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/linjw/code2/Autoformer_custom/run.py\", line 154, in <module>\n",
      "    main()\n",
      "  File \"/home/linjw/code2/Autoformer_custom/run.py\", line 118, in main\n",
      "    exp.train(setting)\n",
      "  File \"/home/linjw/code2/Autoformer_custom/exp/exp_main.py\", line 147, in train\n",
      "    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
      "  File \"/home/linjw/anaconda3/envs/biobase/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/linjw/code2/Autoformer_custom/models/Autoformer.py\", line 87, in forward\n",
      "    enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
      "  File \"/home/linjw/anaconda3/envs/biobase/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/linjw/code2/Autoformer_custom/layers/Embed.py\", line 156, in forward\n",
      "    x = self.value_embedding(x) + self.temporal_embedding(x_mark)\n",
      "  File \"/home/linjw/anaconda3/envs/biobase/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/linjw/code2/Autoformer_custom/layers/Embed.py\", line 62, in forward\n",
      "    x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
      "  File \"/home/linjw/anaconda3/envs/biobase/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/linjw/anaconda3/envs/biobase/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 301, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/linjw/anaconda3/envs/biobase/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 294, in _conv_forward\n",
      "    return F.conv1d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
      "RuntimeError: Given groups=1, weight of size [512, 6, 3], expected input[32, 5, 8] to have 6 channels, but got 5 channels instead\n"
     ]
    }
   ],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=0\n",
    "! python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/ \\\n",
    "  --data_path rawdata.csv \\\n",
    "  --model_id creep \\\n",
    "  --model Autoformer \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 6 \\\n",
    "  --label_len 6 \\\n",
    "  --pred_len 1 \\\n",
    "  --e_layers 1 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 6 \\\n",
    "  --dec_in 6 \\\n",
    "  --c_out 6 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --train_epochs 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型AutoFormer,原始数据集改造成Jena_climate的结果,方便后续对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='weather_96_96', model='Autoformer', data='custom', root_path='./dataset/weather/', data_path='weather_custom.csv', features='M', target='T (degC)', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, bucket_size=4, n_hashes=4, enc_in=14, dec_in=14, c_out=14, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=2, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 36696\n",
      "val 5175\n",
      "test 10444\n",
      "\titers: 100, epoch: 1 | loss: 0.5166370\n",
      "\tspeed: 0.0626s/iter; left time: 137.2287s\n",
      "\titers: 200, epoch: 1 | loss: 0.3645647\n",
      "\tspeed: 0.0495s/iter; left time: 103.6700s\n",
      "\titers: 300, epoch: 1 | loss: 0.3107604\n",
      "\tspeed: 0.0495s/iter; left time: 98.7378s\n",
      "\titers: 400, epoch: 1 | loss: 0.3515287\n",
      "\tspeed: 0.0495s/iter; left time: 93.6503s\n",
      "\titers: 500, epoch: 1 | loss: 0.2805280\n",
      "\tspeed: 0.0495s/iter; left time: 88.7583s\n",
      "\titers: 600, epoch: 1 | loss: 0.3233790\n",
      "\tspeed: 0.0496s/iter; left time: 83.9353s\n",
      "\titers: 700, epoch: 1 | loss: 0.3413942\n",
      "\tspeed: 0.0495s/iter; left time: 78.9106s\n",
      "\titers: 800, epoch: 1 | loss: 0.2676391\n",
      "\tspeed: 0.0496s/iter; left time: 74.0177s\n",
      "\titers: 900, epoch: 1 | loss: 0.3236831\n",
      "\tspeed: 0.0496s/iter; left time: 69.1303s\n",
      "\titers: 1000, epoch: 1 | loss: 1.1816567\n",
      "\tspeed: 0.0497s/iter; left time: 64.2101s\n",
      "\titers: 1100, epoch: 1 | loss: 1.2124858\n",
      "\tspeed: 0.0513s/iter; left time: 61.1485s\n",
      "Epoch: 1 cost time: 58.54187631607056\n",
      "Epoch: 1, Steps: 1146 | Train Loss: 0.3970579 Vali Loss: 0.3108756 Test Loss: 0.2501613\n",
      "Validation loss decreased (inf --> 0.310876).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2710521\n",
      "\tspeed: 0.2815s/iter; left time: 294.6894s\n",
      "\titers: 200, epoch: 2 | loss: 1.2016382\n",
      "\tspeed: 0.0501s/iter; left time: 47.4208s\n",
      "\titers: 300, epoch: 2 | loss: 0.2325395\n",
      "\tspeed: 0.0501s/iter; left time: 42.4069s\n",
      "\titers: 400, epoch: 2 | loss: 0.2697869\n",
      "\tspeed: 0.0499s/iter; left time: 37.2953s\n",
      "\titers: 500, epoch: 2 | loss: 0.2379008\n",
      "\tspeed: 0.0500s/iter; left time: 32.3423s\n",
      "\titers: 600, epoch: 2 | loss: 0.2566241\n",
      "\tspeed: 0.0500s/iter; left time: 27.3369s\n",
      "\titers: 700, epoch: 2 | loss: 0.2268519\n",
      "\tspeed: 0.0500s/iter; left time: 22.3417s\n",
      "\titers: 800, epoch: 2 | loss: 0.2282020\n",
      "\tspeed: 0.0500s/iter; left time: 17.3461s\n",
      "\titers: 900, epoch: 2 | loss: 0.2263342\n",
      "\tspeed: 0.0501s/iter; left time: 12.3697s\n",
      "\titers: 1000, epoch: 2 | loss: 0.3047797\n",
      "\tspeed: 0.0501s/iter; left time: 7.3615s\n",
      "\titers: 1100, epoch: 2 | loss: 0.2137653\n",
      "\tspeed: 0.0501s/iter; left time: 2.3547s\n",
      "Epoch: 2 cost time: 58.27551507949829\n",
      "Epoch: 2, Steps: 1146 | Train Loss: 0.3439415 Vali Loss: 0.3241826 Test Loss: 0.2262822\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      ">>>>>>>testing : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 10444\n",
      "test shape: (326, 32, 96, 14) (326, 32, 96, 14)\n",
      "test shape: (10432, 96, 14) (10432, 96, 14)\n",
      "mse:0.2507050633430481, mae:0.34982770681381226\n"
     ]
    }
   ],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=0\n",
    "! python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/weather/ \\\n",
    "  --data_path weather_custom.csv \\\n",
    "  --model_id weather_96_96 \\\n",
    "  --model Autoformer \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 14 \\\n",
    "  --dec_in 14 \\\n",
    "  --c_out 14 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --train_epochs 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型AutoFormer,Jena_climate数据集的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='weather_96_96', model='Autoformer', data='custom', root_path='./dataset/weather/', data_path='weather_jena_climate.csv', features='M', target='T (degC)', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, bucket_size=4, n_hashes=4, enc_in=14, dec_in=14, c_out=14, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=2, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34809\n",
      "val 4905\n",
      "test 9905\n",
      "\titers: 100, epoch: 1 | loss: 0.3697103\n",
      "\tspeed: 0.0566s/iter; left time: 117.3966s\n",
      "\titers: 200, epoch: 1 | loss: 0.4296638\n",
      "\tspeed: 0.0493s/iter; left time: 97.4026s\n",
      "\titers: 300, epoch: 1 | loss: 0.3905697\n",
      "\tspeed: 0.0494s/iter; left time: 92.6255s\n",
      "\titers: 400, epoch: 1 | loss: 0.4304565\n",
      "\tspeed: 0.0494s/iter; left time: 87.7324s\n",
      "\titers: 500, epoch: 1 | loss: 0.3657482\n",
      "\tspeed: 0.0494s/iter; left time: 82.7703s\n",
      "\titers: 600, epoch: 1 | loss: 0.3877841\n",
      "\tspeed: 0.0495s/iter; left time: 77.8869s\n",
      "\titers: 700, epoch: 1 | loss: 0.3281688\n",
      "\tspeed: 0.0495s/iter; left time: 72.9632s\n",
      "\titers: 800, epoch: 1 | loss: 0.3906828\n",
      "\tspeed: 0.0495s/iter; left time: 68.1151s\n",
      "\titers: 900, epoch: 1 | loss: 0.2926351\n",
      "\tspeed: 0.0496s/iter; left time: 63.1874s\n",
      "\titers: 1000, epoch: 1 | loss: 0.3173504\n",
      "\tspeed: 0.0496s/iter; left time: 58.2624s\n",
      "Epoch: 1 cost time: 54.63208246231079\n",
      "Epoch: 1, Steps: 1087 | Train Loss: 0.3625363 Vali Loss: 0.4157904 Test Loss: 0.3771826\n",
      "Validation loss decreased (inf --> 0.415790).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2450694\n",
      "\tspeed: 0.2903s/iter; left time: 286.7725s\n",
      "\titers: 200, epoch: 2 | loss: 0.3223200\n",
      "\tspeed: 0.0498s/iter; left time: 44.1879s\n",
      "\titers: 300, epoch: 2 | loss: 0.3087622\n",
      "\tspeed: 0.0498s/iter; left time: 39.2710s\n",
      "\titers: 400, epoch: 2 | loss: 0.2763724\n",
      "\tspeed: 0.0500s/iter; left time: 34.3699s\n",
      "\titers: 500, epoch: 2 | loss: 0.2501360\n",
      "\tspeed: 0.0500s/iter; left time: 29.4162s\n",
      "\titers: 600, epoch: 2 | loss: 0.3242438\n",
      "\tspeed: 0.0500s/iter; left time: 24.3953s\n",
      "\titers: 700, epoch: 2 | loss: 0.2926986\n",
      "\tspeed: 0.0500s/iter; left time: 19.4071s\n",
      "\titers: 800, epoch: 2 | loss: 0.2826523\n",
      "\tspeed: 0.0500s/iter; left time: 14.3995s\n",
      "\titers: 900, epoch: 2 | loss: 0.2643937\n",
      "\tspeed: 0.0500s/iter; left time: 9.4092s\n",
      "\titers: 1000, epoch: 2 | loss: 0.2937430\n",
      "\tspeed: 0.0501s/iter; left time: 4.4057s\n",
      "Epoch: 2 cost time: 55.28881478309631\n",
      "Epoch: 2, Steps: 1087 | Train Loss: 0.2948584 Vali Loss: 0.4153891 Test Loss: 0.3860694\n",
      "Validation loss decreased (0.415790 --> 0.415389).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      ">>>>>>>testing : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 9905\n",
      "test shape: (309, 32, 96, 14) (309, 32, 96, 14)\n",
      "test shape: (9888, 96, 14) (9888, 96, 14)\n",
      "mse:0.38676896691322327, mae:0.4135352075099945\n"
     ]
    }
   ],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=0\n",
    "! python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/weather/ \\\n",
    "  --data_path weather_jena_climate.csv \\\n",
    "  --model_id weather_96_96 \\\n",
    "  --model Autoformer \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 14 \\\n",
    "  --dec_in 14 \\\n",
    "  --c_out 14 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --train_epochs 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用模型Transformer,原始数据集改造成Jena_climate的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='weather_96_96', model='Transformer', data='custom', root_path='./dataset/weather/', data_path='weather_custom.csv', features='M', target='T (degC)', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, bucket_size=4, n_hashes=4, enc_in=14, dec_in=14, c_out=14, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=2, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 36696\n",
      "val 5175\n",
      "test 10444\n",
      "\titers: 100, epoch: 1 | loss: 0.2619352\n",
      "\tspeed: 0.0324s/iter; left time: 71.0674s\n",
      "\titers: 200, epoch: 1 | loss: 0.2249535\n",
      "\tspeed: 0.0235s/iter; left time: 49.1839s\n",
      "\titers: 300, epoch: 1 | loss: 0.2337596\n",
      "\tspeed: 0.0236s/iter; left time: 46.9430s\n",
      "\titers: 400, epoch: 1 | loss: 0.2316352\n",
      "\tspeed: 0.0235s/iter; left time: 44.5225s\n",
      "\titers: 500, epoch: 1 | loss: 0.1892690\n",
      "\tspeed: 0.0235s/iter; left time: 42.2039s\n",
      "\titers: 600, epoch: 1 | loss: 0.1646327\n",
      "\tspeed: 0.0236s/iter; left time: 39.9811s\n",
      "\titers: 700, epoch: 1 | loss: 0.2073825\n",
      "\tspeed: 0.0236s/iter; left time: 37.5525s\n",
      "\titers: 800, epoch: 1 | loss: 0.1522968\n",
      "\tspeed: 0.0236s/iter; left time: 35.2476s\n",
      "\titers: 900, epoch: 1 | loss: 0.1380771\n",
      "\tspeed: 0.0236s/iter; left time: 32.8315s\n",
      "\titers: 1000, epoch: 1 | loss: 1.0042701\n",
      "\tspeed: 0.0236s/iter; left time: 30.5465s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1141549\n",
      "\tspeed: 0.0236s/iter; left time: 28.1692s\n",
      "Epoch: 1 cost time: 28.061649560928345\n",
      "Epoch: 1, Steps: 1146 | Train Loss: 0.2639099 Vali Loss: 0.2736788 Test Loss: 0.2747532\n",
      "Validation loss decreased (inf --> 0.273679).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1142875\n",
      "\tspeed: 0.1082s/iter; left time: 113.2352s\n",
      "\titers: 200, epoch: 2 | loss: 0.1196293\n",
      "\tspeed: 0.0236s/iter; left time: 22.3024s\n",
      "\titers: 300, epoch: 2 | loss: 0.9587785\n",
      "\tspeed: 0.0235s/iter; left time: 19.8669s\n",
      "\titers: 400, epoch: 2 | loss: 0.9618052\n",
      "\tspeed: 0.0235s/iter; left time: 17.5552s\n",
      "\titers: 500, epoch: 2 | loss: 0.0972582\n",
      "\tspeed: 0.0236s/iter; left time: 15.2826s\n",
      "\titers: 600, epoch: 2 | loss: 0.1014804\n",
      "\tspeed: 0.0237s/iter; left time: 12.9815s\n",
      "\titers: 700, epoch: 2 | loss: 0.1014579\n",
      "\tspeed: 0.0235s/iter; left time: 10.4959s\n",
      "\titers: 800, epoch: 2 | loss: 0.0940195\n",
      "\tspeed: 0.0235s/iter; left time: 8.1455s\n",
      "\titers: 900, epoch: 2 | loss: 0.0858405\n",
      "\tspeed: 0.0235s/iter; left time: 5.8109s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0930923\n",
      "\tspeed: 0.0235s/iter; left time: 3.4523s\n",
      "\titers: 1100, epoch: 2 | loss: 0.9419134\n",
      "\tspeed: 0.0236s/iter; left time: 1.1104s\n",
      "Epoch: 2 cost time: 27.974208116531372\n",
      "Epoch: 2, Steps: 1146 | Train Loss: 0.1798093 Vali Loss: 0.2854282 Test Loss: 0.2962736\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      ">>>>>>>testing : weather_96_96_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 10444\n",
      "test shape: (326, 32, 96, 14) (326, 32, 96, 14)\n",
      "test shape: (10432, 96, 14) (10432, 96, 14)\n",
      "mse:0.2749776542186737, mae:0.3577501177787781\n"
     ]
    }
   ],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=0\n",
    "! python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/weather/ \\\n",
    "  --data_path weather_custom.csv \\\n",
    "  --model_id weather_96_96 \\\n",
    "  --model Transformer \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 14 \\\n",
    "  --dec_in 14 \\\n",
    "  --c_out 14 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --train_epochs 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用模型Transformer,Jena_climate数据集的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='weather_96_96', model='Transformer', data='custom', root_path='./dataset/weather/', data_path='weather_jena_climate.csv', features='M', target='T (degC)', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, bucket_size=4, n_hashes=4, enc_in=14, dec_in=14, c_out=14, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=2, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34809\n",
      "val 4905\n",
      "test 9905\n",
      "\titers: 100, epoch: 1 | loss: 0.3250677\n",
      "\tspeed: 0.0315s/iter; left time: 65.4601s\n",
      "\titers: 200, epoch: 1 | loss: 0.3293390\n",
      "\tspeed: 0.0235s/iter; left time: 46.3748s\n",
      "\titers: 300, epoch: 1 | loss: 0.2776043\n",
      "\tspeed: 0.0235s/iter; left time: 43.9859s\n",
      "\titers: 400, epoch: 1 | loss: 0.1962035\n",
      "\tspeed: 0.0235s/iter; left time: 41.7641s\n",
      "\titers: 500, epoch: 1 | loss: 0.2070748\n",
      "\tspeed: 0.0235s/iter; left time: 39.4205s\n",
      "\titers: 600, epoch: 1 | loss: 0.1943803\n",
      "\tspeed: 0.0236s/iter; left time: 37.0932s\n",
      "\titers: 700, epoch: 1 | loss: 0.2026431\n",
      "\tspeed: 0.0235s/iter; left time: 34.7010s\n",
      "\titers: 800, epoch: 1 | loss: 0.1414860\n",
      "\tspeed: 0.0235s/iter; left time: 32.3804s\n",
      "\titers: 900, epoch: 1 | loss: 0.1534026\n",
      "\tspeed: 0.0236s/iter; left time: 30.0784s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1617038\n",
      "\tspeed: 0.0237s/iter; left time: 27.8818s\n",
      "Epoch: 1 cost time: 26.533165216445923\n",
      "Epoch: 1, Steps: 1087 | Train Loss: 0.2159751 Vali Loss: 0.4127400 Test Loss: 0.5274249\n",
      "Validation loss decreased (inf --> 0.412740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1418569\n",
      "\tspeed: 0.1151s/iter; left time: 113.6977s\n",
      "\titers: 200, epoch: 2 | loss: 0.1331574\n",
      "\tspeed: 0.0237s/iter; left time: 21.0321s\n",
      "\titers: 300, epoch: 2 | loss: 0.1340891\n",
      "\tspeed: 0.0237s/iter; left time: 18.6398s\n",
      "\titers: 400, epoch: 2 | loss: 0.1211500\n",
      "\tspeed: 0.0236s/iter; left time: 16.2416s\n",
      "\titers: 500, epoch: 2 | loss: 0.1345623\n",
      "\tspeed: 0.0236s/iter; left time: 13.9028s\n",
      "\titers: 600, epoch: 2 | loss: 0.1067785\n",
      "\tspeed: 0.0237s/iter; left time: 11.5462s\n",
      "\titers: 700, epoch: 2 | loss: 0.1141659\n",
      "\tspeed: 0.0237s/iter; left time: 9.1765s\n",
      "\titers: 800, epoch: 2 | loss: 0.1131765\n",
      "\tspeed: 0.0237s/iter; left time: 6.8241s\n",
      "\titers: 900, epoch: 2 | loss: 0.1175354\n",
      "\tspeed: 0.0237s/iter; left time: 4.4553s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1217683\n",
      "\tspeed: 0.0237s/iter; left time: 2.0828s\n",
      "Epoch: 2 cost time: 26.594104051589966\n",
      "Epoch: 2, Steps: 1087 | Train Loss: 0.1245430 Vali Loss: 0.3996102 Test Loss: 0.4835295\n",
      "Validation loss decreased (0.412740 --> 0.399610).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      ">>>>>>>testing : weather_96_96_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 9905\n",
      "test shape: (309, 32, 96, 14) (309, 32, 96, 14)\n",
      "test shape: (9888, 96, 14) (9888, 96, 14)\n",
      "mse:0.48397254943847656, mae:0.5046862959861755\n"
     ]
    }
   ],
   "source": [
    "! export CUDA_VISIBLE_DEVICES=0\n",
    "! python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/weather/ \\\n",
    "  --data_path weather_jena_climate.csv \\\n",
    "  --model_id weather_96_96 \\\n",
    "  --model Transformer \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 14 \\\n",
    "  --dec_in 14 \\\n",
    "  --c_out 14 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --train_epochs 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biobase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4342b7b77d03aa170c0061ccc2d89deb9ee932a6281860c89ed54b64e098c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
