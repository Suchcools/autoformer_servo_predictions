{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    输入dataset 和 checkpoint地址\n",
    "\n",
    "    你的数据集要通过我的制作函函数做成dataset4格式\n",
    "    训练用什么参数 下面就要用什么参数 和best_model_path是对应的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = './checkpoints/step7_Autoformer_custom_ftM_sl17_ll17_pl7_dm512_nh8_el1_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/checkpoint.pth'\n",
    "data_path = 'dataset4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=0, model_id='test', model='Autoformer', data='custom', root_path='./dataset/', data_path='dataset4.csv', features='M', target='3Z', freq='h', checkpoints='./checkpoints/', seq_len=17, label_len=17, pred_len=7, bucket_size=4, n_hashes=4, enc_in=17, dec_in=17, c_out=17, d_model=512, n_heads=8, e_layers=1, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=50, batch_size=64, patience=3, learning_rate=0.0001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--is_training', type=int, required=False, default=0, help='status')\n",
    "parser.add_argument('--model_id', type=str, required=False, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, required=False, default='Autoformer',\n",
    "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, required=False, default='custom', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./dataset/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default= data_path, help='data file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='3Z', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=17, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=17, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=7, help='prediction sequence length')\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--bucket_size', type=int, default=4, help='for Reformer')\n",
    "parser.add_argument('--n_hashes', type=int, default=4, help='for Reformer')\n",
    "parser.add_argument('--enc_in', type=int, default=17, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=17, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=17, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=1, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=3, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=50, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.dvices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "Exp = Exp_Main\n",
    "setting = '1'.format(\n",
    "    args.model_id,\n",
    "    args.model,\n",
    "    args.data,\n",
    "    args.features,\n",
    "    args.seq_len,\n",
    "    args.label_len,\n",
    "    args.pred_len,\n",
    "    args.d_model,\n",
    "    args.n_heads,\n",
    "    args.e_layers,\n",
    "    args.d_layers,\n",
    "    args.d_ff,\n",
    "    args.factor,\n",
    "    args.embed,\n",
    "    args.distil,\n",
    "    args.des, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Informer, Autoformer, Transformer, Reformer\n",
    "model = Autoformer.Model(exp.args).float()\n",
    "# if exp.args.use_multi_gpu and exp.args.use_gpu:\n",
    "#     model = nn.DataParallel(model, device_ids=exp.args.device_ids)\n",
    "# return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 制作预测数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51460\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.timefeatures import time_features\n",
    "import warnings\n",
    "shuffle_flag = False\n",
    "drop_last = False\n",
    "batch_size = args.batch_size\n",
    "freq = args.freq\n",
    "\n",
    "class Dataset_Predict(Dataset):\n",
    "    def __init__(self, root_path, data_path='ETTh1.csv', size=None,\n",
    "                 features='S', target='OT', scale=True, timeenc=0, freq='h'):\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        if size is None:\n",
    "            self.seq_len = 24 * 4 * 4\n",
    "            self.label_len = 24 * 4\n",
    "            self.pred_len = 24 * 4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path, self.data_path))\n",
    "\n",
    "        cols = list(df_raw.columns)\n",
    "        cols.remove(self.target)\n",
    "        cols.remove('date')\n",
    "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
    "\n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.features == 'S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            self.scaler.fit(df_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "\n",
    "        df_stamp = df_raw[['date']]\n",
    "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "            data_stamp = df_stamp.drop(['date'], 1).values\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "        self.data_x = data\n",
    "        self.data_y = data\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n",
    "timeenc = 1\n",
    "data_set = Dataset_Predict(\n",
    "        root_path=args.root_path,\n",
    "        data_path=args.data_path,\n",
    "        size=[args.seq_len, args.label_len, args.pred_len],\n",
    "        features=args.features,\n",
    "        target=args.target,\n",
    "        timeenc=timeenc,\n",
    "        freq=freq\n",
    "    )\n",
    "print(len(data_set))\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    drop_last=drop_last)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51483"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv('./dataset/dataset4.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "preds = []\n",
    "\n",
    "exp.model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(data_loader):\n",
    "        batch_x = batch_x.float().to(exp.device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[2]]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float().to(exp.device)\n",
    "        # encoder - decoder\n",
    "        if exp.args.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if exp.args.output_attention:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        else:\n",
    "            if exp.args.output_attention:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
    "        preds.append(pred)\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "np.save('output/real_prediction.npy', preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51460, 7, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape # 数据量 步长 全部特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51460, 7, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = np.load('output/real_prediction.npy')\n",
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1867.630005</td>\n",
       "      <td>1754.284424</td>\n",
       "      <td>2131.489502</td>\n",
       "      <td>2204.463379</td>\n",
       "      <td>126.818932</td>\n",
       "      <td>78.221825</td>\n",
       "      <td>444.776459</td>\n",
       "      <td>9.590447</td>\n",
       "      <td>152.070572</td>\n",
       "      <td>48.021187</td>\n",
       "      <td>118.309006</td>\n",
       "      <td>24.665787</td>\n",
       "      <td>53.508526</td>\n",
       "      <td>47.071323</td>\n",
       "      <td>115.454460</td>\n",
       "      <td>29.816372</td>\n",
       "      <td>51.273945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1820.166260</td>\n",
       "      <td>1759.241333</td>\n",
       "      <td>2116.440186</td>\n",
       "      <td>2150.069580</td>\n",
       "      <td>139.756256</td>\n",
       "      <td>63.445892</td>\n",
       "      <td>448.493408</td>\n",
       "      <td>9.625212</td>\n",
       "      <td>67.892319</td>\n",
       "      <td>18.493792</td>\n",
       "      <td>116.154724</td>\n",
       "      <td>66.637848</td>\n",
       "      <td>58.194321</td>\n",
       "      <td>93.478958</td>\n",
       "      <td>101.036209</td>\n",
       "      <td>40.430058</td>\n",
       "      <td>63.770309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1768.241943</td>\n",
       "      <td>1764.496216</td>\n",
       "      <td>2150.354736</td>\n",
       "      <td>2366.576416</td>\n",
       "      <td>154.084061</td>\n",
       "      <td>47.765762</td>\n",
       "      <td>475.747955</td>\n",
       "      <td>9.424036</td>\n",
       "      <td>29.135431</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>117.855492</td>\n",
       "      <td>90.855919</td>\n",
       "      <td>74.388741</td>\n",
       "      <td>91.197289</td>\n",
       "      <td>80.533333</td>\n",
       "      <td>47.321491</td>\n",
       "      <td>76.862526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1810.677368</td>\n",
       "      <td>1795.363281</td>\n",
       "      <td>2197.546143</td>\n",
       "      <td>2582.252686</td>\n",
       "      <td>146.740173</td>\n",
       "      <td>33.567905</td>\n",
       "      <td>487.216492</td>\n",
       "      <td>9.297119</td>\n",
       "      <td>-1.919225</td>\n",
       "      <td>-0.594861</td>\n",
       "      <td>109.263893</td>\n",
       "      <td>101.140068</td>\n",
       "      <td>93.549515</td>\n",
       "      <td>69.025604</td>\n",
       "      <td>46.563080</td>\n",
       "      <td>53.229156</td>\n",
       "      <td>86.029472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1901.875610</td>\n",
       "      <td>1828.349487</td>\n",
       "      <td>2218.892334</td>\n",
       "      <td>2692.936768</td>\n",
       "      <td>126.010674</td>\n",
       "      <td>30.213240</td>\n",
       "      <td>473.884705</td>\n",
       "      <td>9.339736</td>\n",
       "      <td>-2.562345</td>\n",
       "      <td>16.336626</td>\n",
       "      <td>94.215149</td>\n",
       "      <td>98.221489</td>\n",
       "      <td>100.274239</td>\n",
       "      <td>41.226452</td>\n",
       "      <td>23.886257</td>\n",
       "      <td>55.688766</td>\n",
       "      <td>82.355293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1989.760864</td>\n",
       "      <td>1849.516479</td>\n",
       "      <td>2224.554932</td>\n",
       "      <td>2733.939453</td>\n",
       "      <td>109.438805</td>\n",
       "      <td>28.556757</td>\n",
       "      <td>454.912933</td>\n",
       "      <td>9.402867</td>\n",
       "      <td>6.405650</td>\n",
       "      <td>30.451944</td>\n",
       "      <td>80.510559</td>\n",
       "      <td>88.094696</td>\n",
       "      <td>101.334503</td>\n",
       "      <td>21.046455</td>\n",
       "      <td>14.952130</td>\n",
       "      <td>57.992477</td>\n",
       "      <td>75.450562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2047.513306</td>\n",
       "      <td>1960.694824</td>\n",
       "      <td>2158.362549</td>\n",
       "      <td>2474.389404</td>\n",
       "      <td>56.007587</td>\n",
       "      <td>45.670795</td>\n",
       "      <td>426.111053</td>\n",
       "      <td>10.218106</td>\n",
       "      <td>50.332405</td>\n",
       "      <td>114.957573</td>\n",
       "      <td>58.141872</td>\n",
       "      <td>117.360703</td>\n",
       "      <td>25.903709</td>\n",
       "      <td>-18.520638</td>\n",
       "      <td>-7.738566</td>\n",
       "      <td>49.010010</td>\n",
       "      <td>32.263119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0            1            2            3           4          5   \\\n",
       "0  1867.630005  1754.284424  2131.489502  2204.463379  126.818932  78.221825   \n",
       "1  1820.166260  1759.241333  2116.440186  2150.069580  139.756256  63.445892   \n",
       "2  1768.241943  1764.496216  2150.354736  2366.576416  154.084061  47.765762   \n",
       "3  1810.677368  1795.363281  2197.546143  2582.252686  146.740173  33.567905   \n",
       "4  1901.875610  1828.349487  2218.892334  2692.936768  126.010674  30.213240   \n",
       "5  1989.760864  1849.516479  2224.554932  2733.939453  109.438805  28.556757   \n",
       "6  2047.513306  1960.694824  2158.362549  2474.389404   56.007587  45.670795   \n",
       "\n",
       "           6          7           8           9           10          11  \\\n",
       "0  444.776459   9.590447  152.070572   48.021187  118.309006   24.665787   \n",
       "1  448.493408   9.625212   67.892319   18.493792  116.154724   66.637848   \n",
       "2  475.747955   9.424036   29.135431    0.035655  117.855492   90.855919   \n",
       "3  487.216492   9.297119   -1.919225   -0.594861  109.263893  101.140068   \n",
       "4  473.884705   9.339736   -2.562345   16.336626   94.215149   98.221489   \n",
       "5  454.912933   9.402867    6.405650   30.451944   80.510559   88.094696   \n",
       "6  426.111053  10.218106   50.332405  114.957573   58.141872  117.360703   \n",
       "\n",
       "           12         13          14         15         16  \n",
       "0   53.508526  47.071323  115.454460  29.816372  51.273945  \n",
       "1   58.194321  93.478958  101.036209  40.430058  63.770309  \n",
       "2   74.388741  91.197289   80.533333  47.321491  76.862526  \n",
       "3   93.549515  69.025604   46.563080  53.229156  86.029472  \n",
       "4  100.274239  41.226452   23.886257  55.688766  82.355293  \n",
       "5  101.334503  21.046455   14.952130  57.992477  75.450562  \n",
       "6   25.903709 -18.520638   -7.738566  49.010010  32.263119  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data_set.inverse_transform(predict[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1867</td>\n",
       "      <td>1754</td>\n",
       "      <td>2131</td>\n",
       "      <td>2204</td>\n",
       "      <td>126</td>\n",
       "      <td>78</td>\n",
       "      <td>444</td>\n",
       "      <td>9</td>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>115</td>\n",
       "      <td>29</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1820</td>\n",
       "      <td>1759</td>\n",
       "      <td>2116</td>\n",
       "      <td>2150</td>\n",
       "      <td>139</td>\n",
       "      <td>63</td>\n",
       "      <td>448</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>66</td>\n",
       "      <td>58</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1768</td>\n",
       "      <td>1764</td>\n",
       "      <td>2150</td>\n",
       "      <td>2366</td>\n",
       "      <td>154</td>\n",
       "      <td>47</td>\n",
       "      <td>475</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>90</td>\n",
       "      <td>74</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>47</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1810</td>\n",
       "      <td>1795</td>\n",
       "      <td>2197</td>\n",
       "      <td>2582</td>\n",
       "      <td>146</td>\n",
       "      <td>33</td>\n",
       "      <td>487</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>101</td>\n",
       "      <td>93</td>\n",
       "      <td>69</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1901</td>\n",
       "      <td>1828</td>\n",
       "      <td>2218</td>\n",
       "      <td>2692</td>\n",
       "      <td>126</td>\n",
       "      <td>30</td>\n",
       "      <td>473</td>\n",
       "      <td>9</td>\n",
       "      <td>-2</td>\n",
       "      <td>16</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>41</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1989</td>\n",
       "      <td>1849</td>\n",
       "      <td>2224</td>\n",
       "      <td>2733</td>\n",
       "      <td>109</td>\n",
       "      <td>28</td>\n",
       "      <td>454</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>101</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2047</td>\n",
       "      <td>1960</td>\n",
       "      <td>2158</td>\n",
       "      <td>2474</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>426</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>114</td>\n",
       "      <td>58</td>\n",
       "      <td>117</td>\n",
       "      <td>25</td>\n",
       "      <td>-18</td>\n",
       "      <td>-7</td>\n",
       "      <td>49</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3    4   5    6   7    8    9    10   11   12  13   14  \\\n",
       "0  1867  1754  2131  2204  126  78  444   9  152   48  118   24   53  47  115   \n",
       "1  1820  1759  2116  2150  139  63  448   9   67   18  116   66   58  93  101   \n",
       "2  1768  1764  2150  2366  154  47  475   9   29    0  117   90   74  91   80   \n",
       "3  1810  1795  2197  2582  146  33  487   9   -1    0  109  101   93  69   46   \n",
       "4  1901  1828  2218  2692  126  30  473   9   -2   16   94   98  100  41   23   \n",
       "5  1989  1849  2224  2733  109  28  454   9    6   30   80   88  101  21   14   \n",
       "6  2047  1960  2158  2474   56  45  426  10   50  114   58  117   25 -18   -7   \n",
       "\n",
       "   15  16  \n",
       "0  29  51  \n",
       "1  40  63  \n",
       "2  47  76  \n",
       "3  53  86  \n",
       "4  55  82  \n",
       "5  57  75  \n",
       "6  49  32  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_set.inverse_transform(predict[0])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biobase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4342b7b77d03aa170c0061ccc2d89deb9ee932a6281860c89ed54b64e098c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
